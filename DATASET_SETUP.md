# Dataset Setup Guide

This document provides instructions on how to download, set up, and add your own datasets to the MASTRO system.

## Table of Contents
- [Available Datasets](#available-datasets)
- [Downloading Datasets](#downloading-datasets)
- [Directory Structure](#directory-structure)
- [Adding Custom Datasets](#adding-custom-datasets)
- [Troubleshooting](#troubleshooting)

## Available Datasets

The MASTRO system currently supports three educational datasets:

1. **OULAD (Open University Learning Analytics Dataset)**
   - Comprehensive dataset from the Open University with VLE interactions, assessments, and student demographics
   - Contains information from multiple courses and presentations

2. **UCI Student Performance Dataset**
   - Dataset from the UCI Machine Learning Repository focusing on student academic performance
   - Contains demographic, social, and academic attributes

3. **XuetangX MOOC Dataset**
   - Dataset from the XuetangX MOOC platform with student interactions and outcomes
   - Contains detailed clickstream data and assessments

## Downloading Datasets

### OULAD Dataset

1. Visit the [Open University Learning Analytics Dataset page](https://www.kaggle.com/datasets/anlgrbz/student-demographics-online-education-dataoulad/data)
2. Register for access to the dataset (requires academic registration)
3. Download the individual CSV files:
   - `assessments.csv`
   - `courses.csv`
   - `studentInfo.csv`
   - `studentRegistration.csv`
   - `studentAssessment.csv`
   - `studentVle.csv`
   - `vle.csv`
4. Place these files in `raw_datasets/OULAD/data/` directory

### UCI Dataset

1. Visit the [UCI Student Performance Dataset page](https://archive.ics.uci.edu/dataset/697/predict+students+dropout+and+academic+success)
2. Download the relevant CSV files
3. Place the file in `raw_datasets/UCI/data.csv`

### XuetangX Dataset

1. Visit the [XuetangX MOOC Dataset page on Kaggle](https://www.kaggle.com/datasets/anasnofal/mooc-data-xuetangx)
2. Create a Kaggle account if you don't have one
3. Accept the dataset terms
4. Download the following files:
   - `Train.csv`
   - `Test.csv`
   - `user_info.csv`
5. Place these files in `raw_datasets/xuetangx/` directory

## Directory Structure

The system expects the following directory structure for raw datasets:

```
MASTRO/
├── raw_datasets/
│   ├── OULAD/
│   │   ├── data/
│   │   │   ├── assessments.csv
│   │   │   ├── courses.csv
│   │   │   ├── studentInfo.csv
│   │   │   ├── studentRegistration.csv
│   │   │   ├── studentAssessment.csv
│   │   │   ├── studentVle.csv
│   │   │   └── vle.csv
│   │   └── oulad_all_combined.csv  (generated by combine script)
│   ├── UCI/
│   │   └── data.csv
│   └── xuetangx/
│       ├── Train.csv
│       ├── Test.csv
│       └── user_info.csv
```

## Combining OULAD Dataset

If you have individual OULAD files, you can combine them into a single file using the provided script:

```bash
python scripts/combine_oulad.py
```

This will create `raw_datasets/OULAD/oulad_all_combined.csv` which serves as a fallback when individual files are not available.

## Adding Custom Datasets

To add your own dataset, follow these steps:

### 1. Format Requirements

Your dataset must contain the following columns:
- `student_id`: Unique identifier for each student
- `dropout`: Target variable (1 for dropout, 0 for persist)

For time-series analysis, you'll also need:
- `snapshot_day`: Days into the course (for temporal analysis)
- And at minimum one of the following feature columns:
  - `clicks_total`: Total interactions
  - `clicks_mean`: Average daily clicks
  - `assessments_completed`: Number of completed assessments
  - `assessment_score_mean`: Average assessment score
  - `days_since_last_activity`: Days since last interaction

### 2. Data Preparation

The system expects time-series data where each student has multiple records corresponding to different points in time (snapshots). For example:

```csv
student_id,snapshot_day,clicks_total,assessments_completed,dropout
1,7,120,2,0
1,14,250,4,0
1,21,300,5,0
2,7,45,1,0
2,14,60,2,1
```

### 3. Modifying Dataloader

To integrate a new dataset, you may need to modify `data/dataloader.py`:

1. Add a new loading function following the same pattern as `load_uci_timeseries()`
2. Update the `main.py` to accept a parameter for your new dataset
3. Ensure your function returns a DataFrame with the required columns

### 4. Example Custom Dataset Loader

Here's an example of how you could implement a loader for a custom dataset:

```python
def load_custom_timeseries(file_path: str, snapshot_days: list) -> pd.DataFrame:
    """
    Load and process custom dataset into time series format
    """
    from utils.logger import log
    from data.timeseries_features import create_temporal_features
    
    log(f"Loading custom dataset from: {file_path}")
    df = pd.read_csv(file_path)
    
    # Add any necessary preprocessing here
    # Ensure the DataFrame contains required columns
    
    # If your data is not in time-series format, convert it
    timeseries_data = []
    
    for student_id in df['student_id'].unique():
        student_data = df[df['student_id'] == student_id]
        
        # Process for each snapshot day
        for snap_day in snapshot_days:
            # Create a record for this student at this snapshot
            record = {
                'student_id': student_id,
                'snapshot_day': snap_day,
                # ... other features based on data up to snapshot day
                'dropout': student_data['dropout'].iloc[0]  # Target variable
            }
            timeseries_data.append(record)
    
    return pd.DataFrame(timeseries_data)
```

### 5. Running with Custom Dataset

Once you've added your dataset loader, you can run the system with:

```bash
python -m main.py --your_dataset_param --N_students 50
```

## Troubleshooting

### Common Issues

#### Missing Required Files
If you get errors about missing files:
1. Make sure you've downloaded all required files for your chosen dataset
2. Verify the file paths match the expected structure
3. Ensure file names match exactly (case-sensitive)

#### Data Format Issues
If you encounter data format errors:
1. Check that your CSV files have the required columns
2. Ensure all numeric columns are properly formatted
3. Verify that the target column is named 'dropout' with values of 0/1

#### Memory Issues
For large datasets, you may encounter memory issues:
1. Reduce the number of students with `--N_students` parameter
2. Use a machine with more RAM
3. Process the data in chunks if possible

### Verification Steps

After setting up your datasets:

1. Verify files exist:
```bash
ls raw_datasets/OULAD/data/
```

2. Run a small test:
```bash
python -m main.py --N_students 10 --folder_path "raw_datasets/OULAD/data"
```

3. Check generated files:
```bash
ls datasets/ results/
```

## Notes for Researchers

- The .gitignore file automatically excludes the `raw_datasets/` and `datasets/` directories to prevent committing large data files
- Processed datasets are cached as `datasets/ts_datasets_[dataset].csv` to avoid reprocessing
- Trained models are saved to `model_save/` and can be reused in subsequent runs

## Questions?

For questions about dataset setup or adding new datasets, please open an issue in the repository or contact the development team.